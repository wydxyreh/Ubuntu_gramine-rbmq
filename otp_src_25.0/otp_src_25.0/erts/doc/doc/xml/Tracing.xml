<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE chapter SYSTEM "chapter.dtd">
<chapter>
<header>
<copyright>
<year>2022</year>
<year>2022</year>
<holder>Ericsson AB. All Rights Reserved.</holder>
</copyright>
<legalnotice>
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
</legalnotice>

<title>Tracing</title>
<prepared>emd2exml</prepared>
<responsible>emd2exml</responsible>
<docno>1</docno>
<approved>yes</approved>
<checked>yes</checked>
<date>2022-5-17</date>
<rev>1</rev>
<file>Tracing.xml</file>
</header>

<section>
<marker id="Implementation"/>
<title>Implementation</title>
<section>
<marker id="Implementation_Call-return-and-exception-tracing"/>
<title>Call, return, and exception tracing</title>

<p>
Tracing is implemented by setting breakpoints in the traced functions,
and sending the appropriate trace messages when they're hit.
</p>

<list type="bulleted"><item>
Call trace messages are sent immediately.

</item>
<item>
Return tracing pushes a frame to the stack which <em>returns to</em> an
instruction that sends a trace message when encountered.

</item>
<item>
Exception tracing also pushes a frame to the stack, but will only send
a trace message if we encounter it in stack scanning while throwing an
exception.

</item></list>
<p>
This means that one must be careful not to use return or exception tracing
on functions that never return, as each call pushes a frame that will
never be removed.
</p>

<p>
Another limitation is that since the breakpoint is in the <em>callee</em> and not
the <em>caller</em>, we're limited to the information we have on function ingress.
This means that we can't actually tell who called us: since we're limited
to inspecting the stack we can only say where we're <em>going to return to</em>,
which is not quite the same thing.
</p>

<p>
As an illustration, when the <c>caller</c> option is enabled all trace messages
from <c>bar/1</c>  will say that they were called from <c>foo/0</c>, even though it
went through a bunch of other functions on the way:
</p>

<code type="none">
foo() -&gt;
    lots(),
    ok.

lots() -&gt;
    &apos;of&apos;().

&apos;of&apos;() -&gt;
    indirections().

indirections() -&gt;
    bar(10).

bar(0) -&gt;
    done;
bar(N) -&gt;
    bar(N - 1).
</code>
</section>

<section>
<marker id="Implementation_Export-tracing"/>
<title>Export tracing</title>

<p>
In the interpreter, breakpoints are set inside the code trampoline for
export entries, and their address vector is updated to point to them.
This way, only remote calls will hit the breakpoint while local calls to
the same function are left alone, but it otherwise acts the same way as
local breakpoints.
</p>

<p>
Things get a bit more involved in the JIT. See <c>BeamAsm.md</c> for more
details.
</p>

</section>

</section>

<section>
<marker id="Setting-breakpoints"/>
<title>Setting breakpoints</title>

<section>
<marker id="Setting-breakpoints_Introduction"/>
<title>Introduction</title>

<p>
Before OTP R16 when trace settings were changed by <c>erlang:trace_pattern</c>,
all other execution in the VM were halted while the trace operation
was carried out in single threaded mode. Similar to code loading, this
can impose a severe problem for availability that grows with the
number of cores.
</p>

<p>
In OTP R16, breakpoints are set in the code without blocking the VM.
Erlang processes may continue executing undisturbed in parallel during the
entire operation. The same base technique is used as for code loading. A
staging area of breakpoints is prepared and then made active with a single
atomic operation.
</p>

</section>

<section>
<marker id="Setting-breakpoints_Redesign-of-Breakpoint-Wheel"/>
<title>Redesign of Breakpoint Wheel</title>

<p>
To make it easier to manage breakpoints without single threaded mode a
redesign of the breakpoint mechanism has been made. The old
"breakpoint wheel" data structure was a circular double-linked list of
breakpoints for each instrumented function. It was invented before the
SMP emulator. To support it in the SMP emulator, is was essentially
expanded to one breakpoint wheel per scheduler. As more breakpoint
types have been added, the implementation have become messy and hard
to understand and maintain.
</p>

<p>
In the new design the old wheel was dropped and instead replaced by
one struct (<c>GenericBp</c>) to hold the data for all types of breakpoints
for each instrumented function. A bit-flag field is used to indicate
what different type of break actions that are enabled.
</p>

</section>

<section>
<marker id="Setting-breakpoints_Same-Same-but-Different"/>
<title>Same Same but Different</title>

<p>
Even though <c>trace_pattern</c> use the same technique as the non-blocking
code loading with replicated generations of data structures and an
atomic switch, the implementations are quite separate from each
other. One initial idea was to use the existing mechanism of code
loading to do a dummy load operation that would make a copy of the
affected modules. That copy could then be instrumented with
breakpoints before making it reachable with the same atomic switch as
done for code loading. This approach seems straight forward but has a
number of shortcomings, one being the large memory footprint when many
modules are instrumented. Another problem is how execution will reach
the new instrumented code. Normally loaded code can only be reached
through external functions calls. Trace settings must be activated
instantaneously without the need of external function calls.
</p>

<p>
The chosen solution is instead for tracing to use the technique of
replication applied on the data structures for breakpoints. Two
generations of breakpoints are kept and identified by index of 0 and
1. The global atomic variables <c>erts_active_bp_index</c> will determine
which generation of breakpoints running code will use.
</p>

</section>

<section>
<marker id="Setting-breakpoints_Atomicity-Without-Atomic-Operations"/>
<title>Atomicity Without Atomic Operations</title>

<p>
Not using the code loading generations (or any other code duplication)
means that <c>trace_pattern</c> must at some point write to the active beam
code in order for running processes to reach the staged breakpoints
structures. This can be done with one single atomic write operation
per instrumented function. The beam instruction words are however read
with normal memory loads and not through the atomic API. The only
guarantee we need is that the written instruction word is seen as
atomic. Either fully written or not at all. This is true for word
aligned write operation on all hardware architectures we use.
</p>

</section>

<section>
<marker id="Setting-breakpoints_Adding-a-new-Breakpoint"/>
<title>Adding a new Breakpoint</title>

<p>
This is a simplified sequence describing what <c>trace_pattern</c> goes
through when adding a new breakpoint.
</p>

<list type="ordered"><item>
<p>Seize exclusive code write permission (suspend process until we get it).
</p>

</item>
<item>
<p>Allocate breakpoint structure <c>GenericBp</c> including both generations.
Set the active part as disabled with a zeroed flagfield. Save the original
instruction word in the breakpoint.
</p>

</item>
<item>
<p>Write a pointer to the breakpoint at offset <c>-sizeof(UWord)</c> from the first
instruction <c>ErtsFuncInfo</c> header.
</p>

</item>
<item>
<p>Set the staging part of the breakpoint as enabled with specified
breakpoint data.
</p>

</item>
<item>
<p>Wait for thread progress.
</p>

</item>
<item>
<p>Write a <c>op_i_generic_breakpoint</c> as the first instruction for the function.
This instruction will execute the breakpoint that it finds at offset
<c>-sizeof(UWord)</c>.
</p>

</item>
<item>
<p>Wait for thread progress.
</p>

</item>
<item>
<p>Commit the breadpoint by switching <c>erts_active_bp_index</c>.
</p>

</item>
<item>
<p>Wait for thread progress.
</p>

</item>
<item>
<p>Prepare for next call to <c>trace_pattern</c> by updating the new staging part
(the old active) of the breakpoint to be identic to the the new active part.
</p>

</item>
<item>
<p>Release code write permission and return from <c>trace_pattern</c>.
</p>
</item></list>
<p>
The code write permission "lock" seized in step 1 is the same as used
by code loading. This will ensure that only one process at a time can
stage new trace settings but it will also prevent concurrent code
loading and make sure we see a consistent view of the beam code during
the entire sequence.
</p>

<p>
Between step 6 and 8, runninng processes might execute the written
<c>op_i_generic_breakpoint</c> instruction. They will get the breakpoint
structure written in step 3, read <c>erts_active_bp_index</c> and execute
the corresponding part of the breakpoint. Before the switch in step 8
becomes visible they will however execute the disabled part of the
breakpoint structure and do nothing other than executing the saved
original instruction.
</p>

</section>

<section>
<marker id="Setting-breakpoints_To-Update-and-Remove-Breakpoints"/>
<title>To Update and Remove Breakpoints</title>

<p>
The above sequence did only describe adding a new breakpoint. We do
basically the same sequence to update the settings of an existing
breakpoint except step 2,3 and 6 can be skipped as it has already been
done.
</p>

<p>
To remove a breakpoint some more steps are needed. The idea is to
first stage the breakpoint as disabled, do the switch, wait for thread
progress and then remove the disabled breakpoint by restoring the
original beam instruction.
</p>

<p>
Here is a more complete sequence that contains both adding, updating
and removing breakpoints.
</p>

<list type="ordered"><item>
<p>Seize exclusive code write permission (suspend process until we get it).
</p>

</item>
<item>
<p>Allocate new breakpoint structures with a disabled active part and
the original beam instruction. Write a pointer to the breakpoint in
<c>ErtsFuncInfo</c> header at offset <c>-sizeof(UWord)</c>.
</p>

</item>
<item>
<p>Update the staging part of all affected breakpoints. Disable
breakpoints that are to be removed.
</p>

</item>
<item>
<p>Wait for thread progress.
</p>

</item>
<item>
<p>Write a <c>op_i_generic_breakpoint</c> as the first instruction for all
functions with new breakpoints.
</p>

</item>
<item>
<p>Wait for thread progress.
</p>

</item>
<item>
<p>Commit all staged breadpoints by switching <c>erts_active_bp_index</c>.
</p>

</item>
<item>
<p>Wait for thread progress.
</p>

</item>
<item>
<p>Restore original beam instruction for disabled breakpoints.
</p>

</item>
<item>
<p>Wait for thread progress.
</p>

</item>
<item>
<p>Prepare for next call to <c>trace_pattern</c> by updating the new
staging area (the old active) for all enabled breakpoints.
</p>

</item>
<item>
<p>Deallocate disabled breakpoint structures.
</p>

</item>
<item>
<p>Release code write permission and return from <c>trace_pattern</c>.
</p>
</item></list>
</section>

<section>
<marker id="Setting-breakpoints_All-that-Waiting-for-Thread-Progress"/>
<title>All that Waiting for Thread Progress</title>

<p>
There are four rounds of waiting for thread progress in the above
sequence. In the code loading sequence we sacrificed memory overhead
of three generations to avoid a second round of thread progress. The
latency of <c>trace_pattern</c> should not be such a big problem for
however, as it is normally not called in a rapid sequence.
</p>

<p>
The waiting in step 4 is to make sure all threads will see an updated
view of the breakpoint structures once they become reachable through
the <c>op_i_generic_breakpoint</c> instruction written in step 5.
</p>

<p>
The waiting in step 6 is to make the activation of the new trace
settings "as atomic as possible". Different cores might see the new
value of <c>erts_active_bp_index</c> at different times as it is read
without any memory barrier. But this is the best we can do without
more expensive thread synchronization.
</p>

<p>
The waiting in step 8 is to make sure we don't restore the original
bream instructions for disabled breakpoints until we know that no
thread is still accessing the old enabled part of a disabled
breakpoint.
</p>

<p>
The waiting in step 10 is to make sure no lingering thread is still
accessing disabled breakpoint structures to be deallocated in step
12.
</p>

</section>

<section>
<marker id="Setting-breakpoints_Global-Tracing"/>
<title>Global Tracing</title>

<p>
Call tracing with <c>global</c> option only affects external function
calls. This was earlier handled by inserting a special trace
instruction in export entries without the use of breakpoints. With the
new non-blocking tracing we want to avoid special handling for global
tracing and make use of the staging and atomic switching within the
breakpoint mechanism. The solution was to create the same type of
breakpoint structure for a global call trace. The difference to local
tracing is that we insert the <c>op_i_generic_breakpoint</c> instruction
(with its pointer at offset -4) in the export entry rather than in the
code.
</p>

</section>

<section>
<marker id="Setting-breakpoints_Future-work"/>
<title>Future work</title>

<p>
We still go to single threaded mode when new code is loaded for a
module that is traced, or when loading code when there is a default
trace pattern set. That is not impossible to fix, but that requires
much closer cooperation between tracing BIFs and the loader BIFs.
</p>
</section>

</section>

</chapter>

